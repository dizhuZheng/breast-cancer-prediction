{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.5.0\n"
     ]
    }
   ],
   "source": [
    "import math, re, os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from matplotlib import pyplot as plt   # matplotlib进行画图\n",
    "from kaggle_datasets import KaggleDatasets # Kaggle数据集\n",
    "import efficientnet.tfkeras as efn    # 导入efficientnet模型\n",
    "# 从python的sklearn机器学习中导入f1值、精度、召回率和混淆矩阵\n",
    "from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix \n",
    "print(\"Tensorflow version \" + tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTO = tf.data.experimental.AUTOTUNE # 可以让程序自动的选择最优的线程并行个数\n",
    "# 从TPU创建部署\n",
    "tpu = tf.distribute.cluster_resolver.TPUClusterResolver() #如果先前设置好了ＴＰＵ＿ＮＡＭＥ环境变量，不需要再给参数．\n",
    "tf.config.experimental_connect_to_cluster(tpu) # 配置实验连接到群集\n",
    "tf.tpu.experimental.initialize_tpu_system(tpu) # 初始化tpu系统\n",
    "strategy = tf.distribute.experimental.TPUStrategy(tpu) # 设置TPU部署\n",
    "GCS_DS_PATH = KaggleDatasets().get_gcs_path('tpu-getting-started')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_SIZE = [512, 512]\n",
    "GCS_PATH = GCS_DS_PATH + '/tfrecords-jpeg-512x512'\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "TRAINING_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/train/*.tfrec')\n",
    "VALIDATION_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/val/*.tfrec')\n",
    "TEST_FILENAMES = tf.io.gfile.glob(GCS_PATH + '/test/*.tfrec') \n",
    "CLASSES = ['pink primrose', 'hard-leaved pocket orchid', 'canterbury bells', 'sweet pea', 'wild geranium', 'tiger lily', 'moon orchid', 'bird of paradise', 'monkshood', 'globe thistle', 'snapdragon', \"colt's foot\", 'king protea', 'spear thistle', 'yellow iris', 'globe-flower', 'purple coneflower', 'peruvian lily', 'balloon flower', 'giant white arum lily', 'fire lily', 'pincushion flower', 'fritillary', 'red ginger', 'grape hyacinth', 'corn poppy', 'prince of wales feathers', 'stemless gentian', 'artichoke', 'sweet william', 'carnation', 'garden phlox', 'love in the mist', 'cosmos', 'alpine sea holly', 'ruby-lipped cattleya', 'cape flower', 'great masterwort', 'siam tulip', 'lenten rose', 'barberton daisy', 'daffodil', 'sword lily', 'poinsettia', 'bolero deep blue', 'wallflower', 'marigold', 'buttercup', 'daisy', 'common dandelion', 'petunia', 'wild pansy', 'primula', 'sunflower', 'lilac hibiscus', 'bishop of llandaff', 'gaura', 'geranium', 'orange dahlia', 'pink-yellow dahlia', 'cautleya spicata', 'japanese anemone', 'black-eyed susan', 'silverbush', 'californian poppy', 'osteospermum', 'spring crocus', 'iris', 'windflower', 'tree poppy', 'gazania', 'azalea', 'water lily', 'rose', 'thorn apple', 'morning glory', 'passion flower', 'lotus', 'toad lily', 'anthurium', 'frangipani', 'clematis', 'hibiscus', 'columbine', 'desert-rose', 'tree mallow', 'magnolia', 'cyclamen ', 'watercress', 'canna lily', 'hippeastrum ', 'bee balm', 'pink quill', 'foxglove', 'bougainvillea', 'camellia', 'mallow', 'mexican petunia', 'bromelia', 'blanket flower', 'trumpet creeper', 'blackberry lily', 'common tulip', 'wild rose']\n",
    "def decode_image(image_data):\n",
    "    image = tf.image.decode_jpeg(image_data, channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # convert image to floats in [0, 1] range\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3]) # explicit size needed for TPU\n",
    "    return image\n",
    "\n",
    "def read_labeled_tfrecord(example):\n",
    "    LABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        \"class\": tf.io.FixedLenFeature([], tf.int64),  # shape [] means single element\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, LABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    label = tf.cast(example['class'], tf.int32)\n",
    "    return image, label # returns a dataset of (image, label) pairs\n",
    "\n",
    "def read_unlabeled_tfrecord(example):\n",
    "    UNLABELED_TFREC_FORMAT = {\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string), # tf.string means bytestring\n",
    "        \"id\": tf.io.FixedLenFeature([], tf.string),  # shape [] means single element\n",
    "        # class is missing, this competitions's challenge is to predict flower classes for the test dataset\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, UNLABELED_TFREC_FORMAT)\n",
    "    image = decode_image(example['image'])\n",
    "    idnum = example['id']\n",
    "    return image, idnum # returns a dataset of image(s)\n",
    "\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    # Read from TFRecords. For optimal performance, reading from multiple files at once and\n",
    "    # disregarding data order. Order does not matter since we will be shuffling the data anyway.\n",
    "    ignore_order = tf.data.Options()\n",
    "    if not ordered:\n",
    "        ignore_order.experimental_deterministic = False #disable order,increase speed\n",
    "    dataset = tf.data.TFRecordDataset(filenames, num_parallel_reads=AUTO) # automatically interleaves reads from multiple files\n",
    "    dataset = dataset.with_options(ignore_order) # uses data as soon as it streams in, rather than in its original order\n",
    "    dataset = dataset.map(read_labeled_tfrecord if labeled else read_unlabeled_tfrecord, num_parallel_calls=AUTO)\n",
    "    # returns a dataset of (image, label) pairs if labeled=True or (image, id) pairs if labeled=False\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_augment(image, label, seed=2020):\n",
    "    # TensorFlow函数：tf.image.random_flip_left_right\n",
    "    # 按水平 (从左向右) 随机翻转图像.\n",
    "    # 以1比2的概率,输出image沿着第二维翻转的内容,即,width.否则按原样输出图像.\n",
    "    # 参数：\n",
    "    # image：形状为[height, width, channels]的三维张量.\n",
    "    # seed：一个Python整数,用于创建一个随机种子.查看tf.set_random_seed行为.\n",
    "    # 返回：一个与image具有相同类型和形状的三维张量.\n",
    "    image = tf.image.random_flip_left_right(image, seed=seed) \n",
    "#     image = tf.image.random_flip_up_down(image, seed=seed)\n",
    "#     image = tf.image.random_brightness(image, 0.1, seed=seed)\n",
    "#     image = tf.image.random_jpeg_quality(image, 85, 100, seed=seed)\n",
    "#     image = tf.image.resize(image, [530, 530])\n",
    "#     image = tf.image.random_crop(image, [512, 512], seed=seed)\n",
    "    #image = tf.image.random_saturation(image, 0, 2)\n",
    "    return image, label   \n",
    "\n",
    "BATCH_SIZE = 16 * strategy.num_replicas_in_sync\n",
    "\n",
    "def get_training_dataset():\n",
    "    dataset = load_dataset(TRAINING_FILENAMES, labeled=True)\n",
    "    dataset = dataset.map(data_augment, num_parallel_calls=AUTO)\n",
    "    # 函数形式：repeat(count=None)\n",
    "    # 参数count:(可选）表示数据集应重复的次数。默认行为（如果count是None或-1）是无限期重复的数据集。\n",
    "    dataset = dataset.repeat() # the training dataset must repeat for several epochs\n",
    "    dataset = dataset.shuffle(2048) #将数据打乱，括号中数值越大，混乱程度越大\n",
    "    dataset = dataset.batch(BATCH_SIZE) # 按照顺序将小批量中样本数目行数据合成一个小批量，最后一个小批量可能小于20\n",
    "    dataset = dataset.prefetch(AUTO) # prefetch next batch while training (autotune prefetch buffer size)\n",
    "    return dataset\n",
    "\n",
    "def get_validation_dataset(ordered=False):\n",
    "    dataset = load_dataset(VALIDATION_FILENAMES, labeled=True, ordered=ordered)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.cache()\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset\n",
    "\n",
    "def get_test_dataset(ordered=False):\n",
    "    dataset = load_dataset(TEST_FILENAMES, labeled=False, ordered=ordered)\n",
    "    dataset = dataset.batch(BATCH_SIZE)\n",
    "    dataset = dataset.prefetch(AUTO)\n",
    "    return dataset\n",
    "\n",
    "def count_data_items(filenames):\n",
    "    # the number of data items is written in the name of the .tfrec\n",
    "    # files, i.e. flowers00-230.tfrec = 230 data items\n",
    "    n = [int(re.compile(r\"-([0-9]*)\\.\").search(filename).group(1)) for filename in filenames]\n",
    "    return np.sum(n)\n",
    "\n",
    "NUM_TRAINING_IMAGES = count_data_items(TRAINING_FILENAMES)\n",
    "NUM_VALIDATION_IMAGES = count_data_items(VALIDATION_FILENAMES)\n",
    "NUM_TEST_IMAGES = count_data_items(TEST_FILENAMES)\n",
    "print('Dataset: {} training images, {} validation images, {} unlabeled test images'.format(NUM_TRAINING_IMAGES, NUM_VALIDATION_IMAGES, NUM_TEST_IMAGES))\n",
    "\n",
    "ds_train = get_training_dataset()\n",
    "ds_valid = get_validation_dataset()\n",
    "ds_test = get_test_dataset()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.0 64-bit ('p3': virtualenvwrapper)",
   "name": "python390jvsc74a57bd00c13263204c156fc1b9a6b5ab587a9cb9cc72936a00a2d253bc14f7b6d36feab"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}